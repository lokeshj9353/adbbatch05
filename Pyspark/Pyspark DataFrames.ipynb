{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bca3599-6b56-42bf-99cd-76f541e876d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Pyspark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a149583-ce57-4ea7-b05b-8250e5f787a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " from pyspark.sql import functions as F\n",
    " from pyspark.sql.types import StructType,StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "796cddb5-1e60-40cb-aae8-30a451ec6df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_rows=[\n",
    "  (100,'sandeep',20000),\n",
    "  (200,'jashu',14000),\n",
    "  (300,'ramya',30000),\n",
    "  (400,'charan',25000),\n",
    "  (500,'reddy',15000)\n",
    "]\n",
    "\n",
    "columns = [\"emp_id\",\"emp_name\",\"salary\"]\n",
    "\n",
    "emp_df = spark.createDataFrame(data = data_rows,schema=columns)\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c42cde7a-f03d-48ef-81a8-508e728f87f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50cd62ee-dd1f-4c5d-ba15-0940425c0225",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(emp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d5c7dd0-6098-4794-ad5c-f77b49f76755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_rows=[\n",
    "  (100,'sandeep',20000),\n",
    "  (200,'jashu',14000),\n",
    "  (300,'ramya',30000),\n",
    "  (400,'charan',25000),\n",
    "  (500,'reddy',15000)\n",
    "]\n",
    "schema = StructType([\n",
    "  StructField(\"emp_id\",IntegerType(),False),\n",
    "  StructField(\"emp_name\",StringType(),True),\n",
    "  StructField(\"salary\",IntegerType(),True),\n",
    "])\n",
    "emp_df = spark.createDataFrame(data = data_rows,schema=schema)\n",
    "emp_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07dfbb01-cd8c-4ab1-8af5-6bdcdc2b5354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df = (\n",
    "    emp_df\n",
    "    .withColumn(\"status\", F.lit(True))\n",
    ")\n",
    "emp_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79308b07-517f-4680-9fc2-ba3294452844",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df = (\n",
    "    emp_df\n",
    "    .withColumnRenamed(\"salary\",\"emp_salary\")\n",
    ")\n",
    "emp_df.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark DataFrames",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
